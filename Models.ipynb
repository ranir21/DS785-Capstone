{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8979b58-b8e6-453c-aa92-626b38e147ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load complaint data\n",
    "complaint_df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "complaint_df['created_date'] = pd.to_datetime(complaint_df['created_date'], errors='coerce')\n",
    "complaint_df = complaint_df.dropna(subset=['incident_zip'])\n",
    "\n",
    "# Clean ZIP code\n",
    "complaint_df['incident_zip'] = complaint_df['incident_zip'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "\n",
    "# Complaint volume per ZIP\n",
    "complaints_per_zip = complaint_df.groupby('incident_zip').size().reset_index(name='total_complaints')\n",
    "\n",
    "# Load demographic data\n",
    "zip_demo = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "zip_demo = zip_demo[zip_demo['Year'] == 2022]\n",
    "zip_demo['ZIP'] = zip_demo['ZIP'].astype(str).str.zfill(5)\n",
    "\n",
    "# Merge datasets\n",
    "merged = complaints_per_zip.merge(zip_demo, left_on='incident_zip', right_on='ZIP', how='left')\n",
    "merged = merged.dropna(subset=['Total Population', 'Median Household Income', 'Male Population', 'Female Population'])\n",
    "\n",
    "# Feature engineering\n",
    "merged['complaints_per_capita'] = merged['total_complaints'] / merged['Total Population']\n",
    "merged['gender_ratio'] = merged['Male Population'] / (merged['Female Population'] + 1e-6)\n",
    "\n",
    "# Linear regression model\n",
    "X = merged[['Median Household Income', 'Total Population', 'gender_ratio']]\n",
    "X = sm.add_constant(X)\n",
    "y = merged['complaints_per_capita']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=merged, x='Median Household Income', y='complaints_per_capita', scatter_kws={'alpha': 0.6})\n",
    "plt.title(\"Complaint Volume per Capita vs. Median Household Income\")\n",
    "plt.xlabel(\"Median Household Income (USD)\")\n",
    "plt.ylabel(\"Complaints per Capita\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 11.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc89bc9-baa4-4ca1-b1e8-d2cee39eeb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7a945-cedf-49d1-afc1-8fd51d8fccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load data\n",
    "complaints = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "demographics = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "demographics = demographics[demographics[\"Year\"] == 2022]\n",
    "demographics[\"ZIP\"] = demographics[\"ZIP\"].astype(str).str.zfill(5)\n",
    "\n",
    "# Preprocessing\n",
    "complaints['created_date'] = pd.to_datetime(complaints['created_date'], errors='coerce')\n",
    "complaints['closed_date'] = pd.to_datetime(complaints['closed_date'], errors='coerce')\n",
    "complaints = complaints.dropna(subset=['created_date', 'closed_date', 'incident_zip', 'complaint_type', 'open_data_channel_type'])\n",
    "\n",
    "complaints['incident_zip'] = complaints['incident_zip'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "complaints['hour'] = complaints['created_date'].dt.hour\n",
    "\n",
    "# Merge income\n",
    "merged = complaints.merge(demographics[['ZIP', 'Median Household Income']], left_on='incident_zip', right_on='ZIP', how='left')\n",
    "merged = merged.dropna(subset=['Median Household Income'])\n",
    "\n",
    "# Target variables\n",
    "merged['is_smartphone'] = merged['open_data_channel_type'].str.upper().eq('MOBILE').astype(int)\n",
    "merged['closed_within_24h'] = ((merged['closed_date'] - merged['created_date']).dt.total_seconds() < 86400).astype(int)\n",
    "\n",
    "# Encode complaint type\n",
    "le = LabelEncoder()\n",
    "merged['complaint_encoded'] = le.fit_transform(merged['complaint_type'])\n",
    "\n",
    "# Features\n",
    "features = ['complaint_encoded', 'Median Household Income', 'hour']\n",
    "\n",
    "# --- Model 1: Predict if complaint came via smartphone ---\n",
    "X1 = merged[features]\n",
    "y1 = merged['is_smartphone']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model1 = LogisticRegression(max_iter=1000, class_weight='balanced') \n",
    "model1.fit(X_train1, y_train1)\n",
    "preds1 = model1.predict(X_test1)\n",
    "\n",
    "print(\"Smartphone Complaint Prediction:\\n\")\n",
    "print(classification_report(y_test1, preds1))\n",
    "\n",
    "# --- Model 2: Predict if closed within 24 hours ---\n",
    "X2 = merged[features]\n",
    "y2 = merged['closed_within_24h']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "model2 = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model2.fit(X_train2, y_train2)\n",
    "preds2 = model2.predict(X_test2)\n",
    "\n",
    "print(\"\\nClosure Within 24 Hours Prediction:\\n\")\n",
    "print(classification_report(y_test2, preds2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92d778-6dfe-4e81-9d53-342aacc0d8a1",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7288c5e-3db6-4ab9-b919-1738cb34bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load data\n",
    "complaints = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "demographics = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "demographics = demographics[demographics[\"Year\"] == 2022]\n",
    "demographics[\"ZIP\"] = demographics[\"ZIP\"].astype(str).str.zfill(5)\n",
    "\n",
    "# Preprocessing\n",
    "complaints['created_date'] = pd.to_datetime(complaints['created_date'], errors='coerce')\n",
    "complaints['closed_date'] = pd.to_datetime(complaints['closed_date'], errors='coerce')\n",
    "complaints = complaints.dropna(subset=['created_date', 'closed_date', 'incident_zip', 'complaint_type', 'open_data_channel_type'])\n",
    "\n",
    "complaints['incident_zip'] = complaints['incident_zip'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "complaints['hour'] = complaints['created_date'].dt.hour\n",
    "\n",
    "# Merge demographic info\n",
    "merged = complaints.merge(demographics[['ZIP', 'Median Household Income']], left_on='incident_zip', right_on='ZIP', how='left')\n",
    "merged = merged.dropna(subset=['Median Household Income'])\n",
    "\n",
    "# Target Variables\n",
    "merged['is_smartphone'] = merged['open_data_channel_type'].str.upper().eq('MOBILE').astype(int)\n",
    "merged['closed_within_24h'] = ((merged['closed_date'] - merged['created_date']).dt.total_seconds() < 86400).astype(int)\n",
    "\n",
    "# Encode complaint type\n",
    "le = LabelEncoder()\n",
    "merged['complaint_encoded'] = le.fit_transform(merged['complaint_type'])\n",
    "\n",
    "# Common features\n",
    "features = ['complaint_encoded', 'Median Household Income', 'hour']\n",
    "\n",
    "# ----------------------\n",
    "# Model 1: Predict Smartphone Complaints\n",
    "# ----------------------\n",
    "X1 = merged[features]\n",
    "y1 = merged['is_smartphone']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "nb1 = GaussianNB()\n",
    "nb1.fit(X_train1, y_train1)\n",
    "preds1 = nb1.predict(X_test1)\n",
    "\n",
    "print(\"Model 1: Predicting Smartphone Complaints\\n\")\n",
    "print(classification_report(y_test1, preds1))\n",
    "\n",
    "# ----------------------\n",
    "# Model 2: Predict Closure Within 24 Hours\n",
    "# ----------------------\n",
    "X2 = merged[features]\n",
    "y2 = merged['closed_within_24h']\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "nb2 = GaussianNB()\n",
    "nb2.fit(X_train2, y_train2)\n",
    "preds2 = nb2.predict(X_test2)\n",
    "\n",
    "print(\"\\nModel 2: Predicting Closure Within 24 Hours\\n\")\n",
    "print(classification_report(y_test2, preds2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34238d2-017f-48c1-9adb-ed64a7e22863",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09879eb0-482f-4a62-a696-69266a3a124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load datasets\n",
    "complaints = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "demographics = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "demographics = demographics[demographics[\"Year\"] == 2022]\n",
    "demographics[\"ZIP\"] = demographics[\"ZIP\"].astype(str).str.zfill(5)\n",
    "\n",
    "# Clean and preprocess\n",
    "complaints['created_date'] = pd.to_datetime(complaints['created_date'], errors='coerce')\n",
    "complaints['closed_date'] = pd.to_datetime(complaints['closed_date'], errors='coerce')\n",
    "complaints = complaints.dropna(subset=['created_date', 'closed_date', 'incident_zip', 'complaint_type', 'open_data_channel_type'])\n",
    "complaints['incident_zip'] = complaints['incident_zip'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "complaints['hour'] = complaints['created_date'].dt.hour\n",
    "\n",
    "# Merge demographic income\n",
    "merged = complaints.merge(demographics[['ZIP', 'Median Household Income']], left_on='incident_zip', right_on='ZIP', how='left')\n",
    "merged = merged.dropna(subset=['Median Household Income'])\n",
    "\n",
    "# Define target variables\n",
    "merged['is_smartphone'] = (merged['open_data_channel_type'].str.upper() == 'MOBILE').astype(int)\n",
    "merged['closed_within_24h'] = ((merged['closed_date'] - merged['created_date']).dt.total_seconds() < 86400).astype(int)\n",
    "\n",
    "# Encode complaint type\n",
    "le = LabelEncoder()\n",
    "merged['complaint_encoded'] = le.fit_transform(merged['complaint_type'])\n",
    "\n",
    "# Feature columns\n",
    "features = ['complaint_encoded', 'Median Household Income', 'hour']\n",
    "\n",
    "### --- MODEL 1: Smartphone Complaints ---\n",
    "X1 = merged[features]\n",
    "y1 = merged['is_smartphone']\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf1.fit(X_train1, y_train1)\n",
    "preds1 = rf1.predict(X_test1)\n",
    "\n",
    "print(\"Smartphone Complaint Prediction:\\n\")\n",
    "print(classification_report(y_test1, preds1, zero_division=0))\n",
    "\n",
    "### --- MODEL 2: Closure Within 24 Hours ---\n",
    "X2 = merged[features]\n",
    "y2 = merged['closed_within_24h']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf2.fit(X_train2, y_train2)\n",
    "preds2 = rf2.predict(X_test2)\n",
    "\n",
    "print(\"\\n Complaint Closure Within 24 Hours Prediction:\\n\")\n",
    "print(classification_report(y_test2, preds2, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35263937-ad79-414e-9b7e-7db1813eb8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Confusion matrix\n",
    "cm1 = confusion_matrix(y_test1, preds1)\n",
    "labels = ['Not Smartphone', 'Smartphone']\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion Matrix: Smartphone Complaint Prediction\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 12.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "cm2 = confusion_matrix(y_test2, preds2)\n",
    "labels = ['Not Closed in 24h', 'Closed in 24h']\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm2, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion Matrix: Closure Within 24 Hours\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 13.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea60235-dd1d-4534-9231-fdd6ab0cf97e",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d31bcb-fb0b-49ca-8c0a-f3130c281170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load Data\n",
    "complaints = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "demographics = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "demographics = demographics[demographics[\"Year\"] == 2022]\n",
    "demographics[\"ZIP\"] = demographics[\"ZIP\"].astype(str).str.zfill(5)\n",
    "\n",
    "# Preprocessing\n",
    "complaints['created_date'] = pd.to_datetime(complaints['created_date'], errors='coerce')\n",
    "complaints['closed_date'] = pd.to_datetime(complaints['closed_date'], errors='coerce')\n",
    "complaints = complaints.dropna(subset=['created_date', 'closed_date', 'incident_zip', 'complaint_type', 'open_data_channel_type'])\n",
    "\n",
    "complaints['incident_zip'] = complaints['incident_zip'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "complaints['hour'] = complaints['created_date'].dt.hour\n",
    "\n",
    "# Merge income\n",
    "merged = complaints.merge(demographics[['ZIP', 'Median Household Income']], left_on='incident_zip', right_on='ZIP', how='left')\n",
    "merged = merged.dropna(subset=['Median Household Income'])\n",
    "\n",
    "# Encode target variables\n",
    "merged['is_smartphone'] = merged['open_data_channel_type'].str.upper().eq('MOBILE').astype(int)\n",
    "merged['closed_within_24h'] = ((merged['closed_date'] - merged['created_date']).dt.total_seconds() < 86400).astype(int)\n",
    "\n",
    "# Encode complaint type\n",
    "le = LabelEncoder()\n",
    "merged['complaint_encoded'] = le.fit_transform(merged['complaint_type'])\n",
    "\n",
    "# Features to use\n",
    "features = ['complaint_encoded', 'Median Household Income', 'hour']\n",
    "\n",
    "# -----------------------------\n",
    "# 🚀 Model 1: Smartphone Complaints\n",
    "# -----------------------------\n",
    "X1 = merged[features]\n",
    "y1 = merged['is_smartphone']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb1 = XGBClassifier(eval_metric='logloss', scale_pos_weight=3)\n",
    "xgb1.fit(X_train1, y_train1)\n",
    "preds1 = xgb1.predict(X_test1)\n",
    "\n",
    "print(\"Smartphone Complaint Prediction:\\n\")\n",
    "print(classification_report(y_test1, preds1))\n",
    "\n",
    "# -----------------------------\n",
    "# ⏱️ Model 2: Closure Within 24h\n",
    "# -----------------------------\n",
    "X2 = merged[features]\n",
    "y2 = merged['closed_within_24h']\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb2 = XGBClassifier(eval_metric='logloss')\n",
    "xgb2.fit(X_train2, y_train2)\n",
    "preds2 = xgb2.predict(X_test2)\n",
    "\n",
    "print(\"\\n Closure Within 24 Hours Prediction:\\n\")\n",
    "print(classification_report(y_test2, preds2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789cead0-cb9a-4d18-9f94-4e05284e726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assume X, y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', scale_pos_weight=3)\n",
    "}\n",
    "\n",
    "# Store metrics\n",
    "metrics_dict = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    report = classification_report(y_test, preds, output_dict=True, zero_division=0)\n",
    "    print(name)\n",
    "    print(report['weighted avg']['precision'])\n",
    "    print(report['weighted avg']['recall'])\n",
    "    print(report['weighted avg']['f1-score'])\n",
    "    print(report['weighted avg']['support'])\n",
    "    print(accuracy_score(y_test, preds))\n",
    "    metrics_dict[name] = {\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1-score': report['weighted avg']['f1-score'],\n",
    "        'support': report['weighted avg']['support'],\n",
    "        'accuracy': accuracy_score(y_test, preds)\n",
    "    }\n",
    "\n",
    "# Create DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_dict).T\n",
    "\n",
    "# Plot\n",
    "metrics_df.drop(columns=['support']).plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Comparison: Precision, Recall, F1, Accuracy')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 14.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e87d8-6408-4536-8b98-54fc29278713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
