{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924a9f9-2929-4fda-b423-7b4e55b9fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols_to_load = ['Created Date','Closed Date','Incident Zip', 'Agency', 'Agency Name','Complaint Type', 'Status', 'Open Data Channel Type','Latitude', 'Longitude', 'Location','Borough']\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_merged.csv\", usecols=cols_to_load, low_memory=False)\n",
    "\n",
    "df['Created Date'] = pd.to_datetime(df['Created Date'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
    "df['Closed Date'] = pd.to_datetime(df['Closed Date'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
    "\n",
    "# 3. Rename multiple columns at once\n",
    "df.rename(columns={\n",
    "    'Created Date': 'created_date',\n",
    "    'Open Data Channel Type': 'open_data_channel_type',\n",
    "    'Incident Zip': 'incident_zip',\n",
    "    'Closed Date': 'closed_date',\n",
    "    'Complaint Type': 'complaint_type',\n",
    "    'Agency': 'agency',\n",
    "    'Agency Name': 'agency_name',\n",
    "    'Status': 'status',\n",
    "    'Latitude': 'latitude',\n",
    "    'Longitude':'longitude',\n",
    "    'Borough': 'borough'\n",
    "    # â€¦\n",
    "}, inplace=True)\n",
    "df.to_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb98a6-c970-407a-8fb4-bfeb38e69c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "\n",
    "# Convert to datetime\n",
    "df['created_date'] = pd.to_datetime(df['created_date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Drop rows with missing date or channel info\n",
    "df = df.dropna(subset=['created_date', 'open_data_channel_type'])\n",
    "\n",
    "# Classify device type\n",
    "def classify_device(channel):\n",
    "    channel = str(channel).strip().upper()\n",
    "    if channel == 'MOBILE':\n",
    "        return 'Smartphone'\n",
    "    return 'Other'\n",
    "\n",
    "df['device_type'] = df['open_data_channel_type'].apply(classify_device)\n",
    "\n",
    "# Create a monthly period\n",
    "df['year_month'] = df['created_date'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Group by month and device\n",
    "monthly_complaints = (\n",
    "    df.groupby(['year_month', 'device_type'])\n",
    "    .size()\n",
    "    .reset_index(name='complaint_count')\n",
    ")\n",
    "\n",
    "# Pivot for plotting\n",
    "pivot_df = monthly_complaints.pivot(index='year_month', columns='device_type', values='complaint_count').fillna(0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "pivot_df.plot(marker='o')\n",
    "plt.title('Monthly 311 Complaint Volume by Device Type')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Complaint Count')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Device Type')\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 1.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056dab18-d259-4c0d-b14d-7f5089f329bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Load Complaint Data ---\n",
    "complaint_df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "\n",
    "complaint_df['created_date'] = pd.to_datetime(df['created_date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Classify device type\n",
    "def classify_device(channel):\n",
    "    channel = str(channel).strip().upper()\n",
    "    return 'Smartphone' if channel == 'MOBILE' else 'Other'\n",
    "\n",
    "complaint_df['device_type'] = complaint_df['open_data_channel_type'].apply(classify_device)\n",
    "\n",
    "complaint_df['year_month'] = complaint_df['created_date'].dt.to_period('M').astype(str)\n",
    "\n",
    "complaint_df = complaint_df.dropna(subset=['incident_zip'])\n",
    "\n",
    "complaint_df['incident_zip'] = complaint_df['incident_zip'].astype(str).str.split('.').str[0]\n",
    "\n",
    "# --- Step 2: Load ZIP-level Demographic Data ---\n",
    "# Assume you've saved the demographic data shown in your screenshot as 'zip_demographics.csv'\n",
    "zip_demo = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "zip_demo = zip_demo[zip_demo['Year'] == 2022]  # Use latest available year\n",
    "zip_demo['ZIP'] = zip_demo['ZIP'].astype(str).str.zfill(5)\n",
    "\n",
    "# --- Step 3: Normalize Smartphone Complaints by Population ---\n",
    "# Filter for mobile-originated complaints\n",
    "mobile_df = complaint_df[complaint_df['device_type'] == 'Smartphone']\n",
    "\n",
    "# Count complaints per ZIP\n",
    "complaints_per_zip = mobile_df.groupby('incident_zip').size().reset_index(name='smartphone_complaints')\n",
    "\n",
    "# Merge with population and income\n",
    "merged = complaints_per_zip.merge(zip_demo, left_on='incident_zip', right_on='ZIP', how='left')\n",
    "\n",
    "# Calculate complaints per 1000 people\n",
    "merged['complaints_per_1000'] = merged['smartphone_complaints'] / (merged['Total Population'] / 1000)\n",
    "\n",
    "# Load and prepare your merged dataset from earlier steps\n",
    "# Ensure columns: 'Median Household Income' and 'complaints_per_1000'\n",
    "data = merged[['incident_zip', 'Median Household Income', 'complaints_per_1000']].dropna()\n",
    "\n",
    "# --- Linear Regression for Residual Calculation ---\n",
    "X = sm.add_constant(data['Median Household Income'])\n",
    "model = sm.OLS(data['complaints_per_1000'], X).fit()\n",
    "data['predicted'] = model.predict(X)\n",
    "data['residual'] = data['complaints_per_1000'] - data['predicted']\n",
    "\n",
    "# --- Outlier Detection ---\n",
    "std_resid = data['residual'].std()\n",
    "data['outlier'] = abs(data['residual']) > 2 * std_resid\n",
    "\n",
    "# --- Remove Outliers ---\n",
    "data_no_outliers = data[~data['outlier']].copy()\n",
    "\n",
    "# --- LOWESS Smoothing on cleaned data ---\n",
    "lowess = sm.nonparametric.lowess\n",
    "smoothed = lowess(data_no_outliers['complaints_per_1000'], data_no_outliers['Median Household Income'], frac=0.3)\n",
    "\n",
    "# --- Linear Regression Line (already calculated earlier, reusing model) ---\n",
    "X_clean = sm.add_constant(data_no_outliers['Median Household Income'])\n",
    "data_no_outliers['predicted'] = model.predict(X_clean)\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=data_no_outliers, x='Median Household Income', y='complaints_per_1000', color='blue', alpha=0.6)\n",
    "plt.plot(data_no_outliers['Median Household Income'], data_no_outliers['predicted'], color='black', linestyle='--', label='Linear Regression')\n",
    "plt.plot(smoothed[:, 0], smoothed[:, 1], color='green', linestyle='-', label='LOWESS Smoothing')\n",
    "plt.title(\"Smartphone Complaints per 1,000 vs. Median Household Income (Outliers Removed)\")\n",
    "plt.xlabel(\"Median Household Income (USD)\")\n",
    "plt.ylabel(\"Smartphone Complaints per 1,000 Residents\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 2.png\", dpi=300)\n",
    "plt.show()\n",
    "correlation = merged[['Median Household Income', 'complaints_per_1000']].corr().iloc[0, 1]\n",
    "print(f\"Correlation between income and mobile complaints per 1000: {correlation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d28cd-2be9-433c-a592-5907b8778b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(merged['Male Population'], merged['Female Population'], alpha=0.7, c=merged['complaints_per_1000'], cmap='viridis')\n",
    "plt.title(\"Gender Population per ZIP vs. Mobile Complaints per 1,000 Residents\")\n",
    "plt.xlabel(\"Male Population\")\n",
    "plt.ylabel(\"Female Population\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"Mobile Complaints per 1,000 Residents\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 3.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb3b42-505a-4984-ab23-56adf4577e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def bucket_hour(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour < 24:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "        \n",
    "# Load data\n",
    "df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\cleaneddata_single_updated.csv\", low_memory=False)\n",
    "\n",
    "# Convert to datetime\n",
    "df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')\n",
    "df['closed_date'] = pd.to_datetime(df['closed_date'], errors='coerce')\n",
    "\n",
    "# Extract time-based features\n",
    "df['day_of_week'] = df['created_date'].dt.day_name()\n",
    "df['hour'] = df['created_date'].dt.hour\n",
    "df['month'] = df['created_date'].dt.month\n",
    "df['year'] = df['created_date'].dt.year\n",
    "df['time_bucket'] = df['hour'].apply(bucket_hour)\n",
    "\n",
    "# Calculate response time in days\n",
    "df['response_time_days'] = (df['closed_date'] - df['created_date']).dt.total_seconds() / (60 * 60 * 24)\n",
    "\n",
    "# Preview result\n",
    "#print(df[['created_date', 'closed_date', 'day_of_week', 'hour', 'month', 'year', 'response_time_days']].head())\n",
    "\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_counts = df['day_of_week'].value_counts().reindex(dow_order)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "dow_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Complaint Volume by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Complaints')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "df['is_weekend'] = df['day_of_week'].isin(['Saturday', 'Sunday'])\n",
    "\n",
    "# Group by agency and weekend\n",
    "weekend_response = df.groupby(['agency', 'is_weekend'])['response_time_days'].mean().reset_index()\n",
    "\n",
    "# Pivot for comparison\n",
    "pivot = weekend_response.pivot(index='agency', columns='is_weekend', values='response_time_days')\n",
    "pivot.columns = ['Weekday_Avg_Response', 'Weekend_Avg_Response']\n",
    "pivot['Weekend_Slower_by_days'] = pivot['Weekend_Avg_Response'] - pivot['Weekday_Avg_Response']\n",
    "\n",
    "#print(pivot.sort_values(by='Weekend_Slower_by_days', ascending=False))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `pivot` DataFrame is already created from the earlier step\n",
    "pivot_clean = pivot.dropna().sort_values(by='Weekend_Slower_by_days', ascending=False)\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "pivot_clean['Weekend_Slower_by_days'].plot(kind='bar', color='tomato')\n",
    "plt.title('Average Weekend Response Delay by Agency (in Days)')\n",
    "plt.ylabel('Weekend - Weekday Avg Response Time (Days)')\n",
    "plt.xlabel('Agency')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 4.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b06b566-9dc9-4230-bd1d-b098f24219f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bucket_hour(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour < 24:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "        \n",
    "# Load data\n",
    "df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "\n",
    "# Convert to datetime\n",
    "df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')\n",
    "df['closed_date'] = pd.to_datetime(df['closed_date'], errors='coerce')\n",
    "\n",
    "# Extract time-based features\n",
    "df['hour'] = df['created_date'].dt.hour\n",
    "\n",
    "hourly = df['hour'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(hourly.index, hourly.values, marker='o')\n",
    "plt.title('Complaint Volume by Hour of Day')\n",
    "plt.xlabel('Hour (0-23)')\n",
    "plt.ylabel('Number of Complaints')\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 5.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd8c25-599d-4fb1-90f0-0905389e2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "\n",
    "# Convert date columns\n",
    "df['created_date'] = pd.to_datetime(df['created_date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['closed_date'] = pd.to_datetime(df['closed_date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Drop rows with missing report channel\n",
    "df = df.dropna(subset=['open_data_channel_type'])\n",
    "\n",
    "# Create closure flag\n",
    "df['is_closed'] = df['closed_date'].notna().astype(int)\n",
    "\n",
    "# Clean and standardize channel names\n",
    "df['channel'] = df['open_data_channel_type'].str.strip().str.upper()\n",
    "\n",
    "# Group by channel and calculate metrics\n",
    "channel_kpis = df.groupby('channel').agg(\n",
    "    total_complaints=('channel', 'count'),\n",
    "    closure_rate=('is_closed', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Convert closure rate to percentage\n",
    "channel_kpis['closure_rate'] = (channel_kpis['closure_rate'] * 100).round(1)\n",
    "\n",
    "# Display results\n",
    "print(channel_kpis)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(channel_kpis['channel'], channel_kpis['closure_rate'], color='skyblue')\n",
    "plt.ylabel('Closure Rate (%)')\n",
    "plt.xlabel('Report Channel')\n",
    "plt.title('Closure Rate by Report Channel')\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 6.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1e77b-d666-4d71-a9be-7c9e2dd03894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "complaint_df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "# Convert datetime\n",
    "complaint_df['created_date'] = pd.to_datetime(complaint_df['created_date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "complaint_df['closed_date'] = pd.to_datetime(complaint_df['closed_date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Clean up zip codes\n",
    "complaint_df = complaint_df.dropna(subset=['incident_zip'])\n",
    "complaint_df['incident_zip'] = complaint_df['incident_zip'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "\n",
    "# Classify device type\n",
    "def classify_device(channel):\n",
    "    channel = str(channel).strip().upper()\n",
    "    return 'Smartphone' if channel == 'MOBILE' else 'Other'\n",
    "\n",
    "complaint_df['device_type'] = complaint_df['open_data_channel_type'].apply(classify_device)\n",
    "\n",
    "# --- Load demographic data ---\n",
    "zip_demo = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "zip_demo = zip_demo[zip_demo['Year'] == 2022]\n",
    "zip_demo['ZIP'] = zip_demo['ZIP'].astype(str).str.zfill(5)\n",
    "\n",
    "# --- Merge and compute KPIs ---\n",
    "mobile_df = complaint_df[complaint_df['device_type'] == 'Smartphone']\n",
    "\n",
    "# Count complaints per ZIP\n",
    "complaints_per_zip = mobile_df.groupby('incident_zip').size().reset_index(name='smartphone_complaints')\n",
    "\n",
    "# Get borough info per ZIP (most common borough for each ZIP)\n",
    "zip_borough_map = (\n",
    "    mobile_df.groupby('incident_zip')['borough']\n",
    "    .agg(lambda x: x.mode()[0] if not x.mode().empty else None)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Combine complaint counts and borough info\n",
    "complaints_per_zip = complaints_per_zip.merge(zip_borough_map, on='incident_zip', how='left')\n",
    "\n",
    "# Merge with demographic data\n",
    "merged_df = complaints_per_zip.merge(zip_demo, left_on='incident_zip', right_on='ZIP', how='left')\n",
    "\n",
    "# Drop rows with missing population or income\n",
    "merged_df = merged_df.dropna(subset=['Median Household Income', 'Total Population'])\n",
    "\n",
    "# Normalize by population\n",
    "merged_df['complaints_per_1000'] = merged_df['smartphone_complaints'] / (merged_df['Total Population'] / 1000)\n",
    "\n",
    "# Sort top 10 ZIPs by complaint volume\n",
    "top10_df = merged_df.sort_values('smartphone_complaints', ascending=False).head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Bar plot of smartphone complaints\n",
    "bar = sns.barplot(data=top10_df,\n",
    "                  x='incident_zip',\n",
    "                  y='smartphone_complaints',\n",
    "                  hue='borough',\n",
    "                  dodge=False)\n",
    "\n",
    "plt.title(\"Top 10 ZIP Codes by Smartphone Complaints (Normalized by Population)\")\n",
    "plt.xlabel(\"ZIP Code\")\n",
    "plt.ylabel(\"Number of Smartphone Complaints\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Borough')\n",
    "plt.tight_layout\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 7.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b92f2-54ea-419e-9602-92cdfb875036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "complaint_df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "# Convert datetime\n",
    "complaint_df['created_date'] = pd.to_datetime(complaint_df['created_date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "complaint_df['closed_date'] = pd.to_datetime(complaint_df['closed_date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Clean up zip codes\n",
    "complaint_df = complaint_df.dropna(subset=['incident_zip'])\n",
    "complaint_df['incident_zip'] = complaint_df['incident_zip'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "\n",
    "# Classify device type\n",
    "def classify_device(channel):\n",
    "    channel = str(channel).strip().upper()\n",
    "    return 'Smartphone' if channel == 'MOBILE' else 'Other'\n",
    "\n",
    "complaint_df['device_type'] = complaint_df['open_data_channel_type'].apply(classify_device)\n",
    "\n",
    "# --- Load demographic data ---\n",
    "zip_demo = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "zip_demo = zip_demo[zip_demo['Year'] == 2022]\n",
    "zip_demo['ZIP'] = zip_demo['ZIP'].astype(str).str.zfill(5)\n",
    "\n",
    "# --- Merge and compute KPIs ---\n",
    "mobile_df = complaint_df[complaint_df['device_type'] == 'Smartphone']\n",
    "\n",
    "# Count complaints per ZIP\n",
    "complaints_per_zip = mobile_df.groupby('incident_zip').size().reset_index(name='smartphone_complaints')\n",
    "\n",
    "# Get borough info per ZIP (most common borough for each ZIP)\n",
    "zip_borough_map = (\n",
    "    mobile_df.groupby('incident_zip')['borough']\n",
    "    .agg(lambda x: x.mode()[0] if not x.mode().empty else None)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Combine complaint counts and borough info\n",
    "complaints_per_zip = complaints_per_zip.merge(zip_borough_map, on='incident_zip', how='left')\n",
    "\n",
    "# Merge with demographic data\n",
    "merged_df = complaints_per_zip.merge(zip_demo, left_on='incident_zip', right_on='ZIP', how='left')\n",
    "\n",
    "# Drop rows with missing population or income\n",
    "merged_df = merged_df.dropna(subset=['Median Household Income', 'Total Population'])\n",
    "\n",
    "# Normalize by population\n",
    "merged_df['complaints_per_1000'] = merged_df['smartphone_complaints'] / (merged_df['Total Population'] / 1000)\n",
    "\n",
    "# Get top 10 ZIPs by smartphone complaints\n",
    "top10_df = merged_df.nlargest(10, 'smartphone_complaints')\n",
    "\n",
    "# --- PLOTTING ---\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Bar chart: smartphone complaints\n",
    "colors = sns.color_palette(\"tab10\", n_colors=top10_df['borough'].nunique())\n",
    "borough_color_map = dict(zip(top10_df['borough'].unique(), colors))\n",
    "bar_colors = top10_df['borough'].map(borough_color_map)\n",
    "\n",
    "bars = ax1.bar(top10_df['incident_zip'], top10_df['smartphone_complaints'], color=bar_colors)\n",
    "ax1.set_ylabel(\"Smartphone Complaints\", color='black')\n",
    "ax1.set_xlabel(\"ZIP Code\")\n",
    "ax1.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Line chart: median household income\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(top10_df['incident_zip'], top10_df['Median Household Income'], marker='o', color='black', linestyle='--', label='Median Income')\n",
    "ax2.set_ylabel(\"Median Household Income (USD)\", color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Title and legend\n",
    "plt.title(\"Top 10 ZIP Codes by Smartphone Complaints with Median Income\")\n",
    "ax2.legend(loc='upper right')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 8.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba69e4-001d-4803-b35c-1e8f855ccc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load complaint and ZIP demographic data\n",
    "complaint_df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "zip_demo = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\nyc_zip_income_pop_gender_2019_2022.csv\")\n",
    "\n",
    "# Preprocess date and ZIP columns\n",
    "complaint_df['created_date'] = pd.to_datetime(complaint_df['created_date'], errors='coerce')\n",
    "complaint_df['closed_date'] = pd.to_datetime(complaint_df['closed_date'], errors='coerce')\n",
    "complaint_df['incident_zip'] = complaint_df['incident_zip'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "\n",
    "zip_demo = zip_demo[zip_demo['Year'] == 2022]\n",
    "zip_demo['ZIP'] = zip_demo['ZIP'].astype(str).str.zfill(5)\n",
    "\n",
    "# Filter only valid dates\n",
    "complaint_df = complaint_df.dropna(subset=['created_date', 'closed_date'])\n",
    "\n",
    "# Calculate resolution time in hours\n",
    "complaint_df['resolution_time_hrs'] = (complaint_df['closed_date'] - complaint_df['created_date']).dt.total_seconds() / 3600\n",
    "\n",
    "# Group by ZIP and compute average resolution time\n",
    "resolution_by_zip = complaint_df.groupby('incident_zip')['resolution_time_hrs'].mean().reset_index()\n",
    "resolution_by_zip.rename(columns={'incident_zip': 'ZIP', 'resolution_time_hrs': 'avg_resolution_time_hrs'}, inplace=True)\n",
    "\n",
    "# Merge with ZIP-level income data\n",
    "merged = pd.merge(resolution_by_zip, zip_demo[['ZIP', 'Median Household Income']], on='ZIP', how='left')\n",
    "merged = merged.dropna(subset=['Median Household Income', 'avg_resolution_time_hrs'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.regplot(\n",
    "    data=merged,\n",
    "    x='Median Household Income',\n",
    "    y='avg_resolution_time_hrs',\n",
    "    scatter_kws={'alpha': 0.6},\n",
    "    line_kws={'color': 'red'}\n",
    ")\n",
    "plt.title('Average Resolution Time vs Median Household Income')\n",
    "plt.xlabel('Median Household Income (USD)')\n",
    "plt.ylabel('Average Complaint Resolution Time (hrs)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 9.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52e539-3c6d-448d-916d-5214be6e412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"D:\\\\Rekha\\\\Capstone\\\\Data\\\\Cleaned\\\\311_cleaned_final.csv\", low_memory=False)\n",
    "\n",
    "# Drop rows with missing coordinates or complaint type\n",
    "df = df.dropna(subset=['latitude', 'longitude', 'complaint_type'])\n",
    "\n",
    "# Filter top 5 complaint types\n",
    "top_complaints = df['complaint_type'].value_counts().nlargest(20).index\n",
    "df_top = df[df['complaint_type'].isin(top_complaints)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=df_top,\n",
    "    x='longitude',\n",
    "    y='latitude',\n",
    "    hue='complaint_type',\n",
    "    alpha=0.5,\n",
    "    s=10\n",
    ")\n",
    "\n",
    "plt.title('Geographic Distribution of Top 20 Complaint Types')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend(title='Complaint Type', loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:\\\\Rekha\\\\Capstone\\\\Visualizations\\\\Figure 10.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
